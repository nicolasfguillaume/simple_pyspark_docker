{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark - Part 3 - DataFrames and SQL\n",
    "\n",
    "https://datascience-school.com/blog/practical-apache-spark-in-10-minutes.-part-3-dataframes-and-sql/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Spark instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark \n",
    "from pyspark.sql import SQLContext\n",
    "sc = pyspark.SparkContext('local[*]')\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[793, 160, 681, 339, 787]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = sc.parallelize(range(1000))\n",
    "rdd.takeSample(False, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = sqlContext.read.format('csv') \\\n",
    "               .option(\"delimiter\", \",\")\\\n",
    "               .options(header='true', inferschema='true') \\\n",
    "               .load('data/movies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+\n",
      "|movieId|               title|              genres|\n",
      "+-------+--------------------+--------------------+\n",
      "|      1|    Toy Story (1995)|Adventure|Animati...|\n",
      "|      2|      Jumanji (1995)|Adventure|Childre...|\n",
      "|      3|Grumpier Old Men ...|      Comedy|Romance|\n",
      "|      4|Waiting to Exhale...|Comedy|Drama|Romance|\n",
      "|      5|Father of the Bri...|              Comedy|\n",
      "+-------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|               title|              genres|\n",
      "+--------------------+--------------------+\n",
      "|    Toy Story (1995)|Adventure|Animati...|\n",
      "|      Jumanji (1995)|Adventure|Childre...|\n",
      "|Grumpier Old Men ...|      Comedy|Romance|\n",
      "+--------------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies.select(\"title\", \"genres\").show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = sqlContext.read.format('csv') \\\n",
    "               .option(\"delimiter\", \",\")\\\n",
    "               .options(header='true', inferschema='true') \\\n",
    "               .load('data/ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+---------+\n",
      "|userId|movieId|rating|timestamp|\n",
      "+------+-------+------+---------+\n",
      "|     1|      1|   4.0|964982703|\n",
      "|     1|      3|   4.0|964981247|\n",
      "|     1|      6|   4.0|964982224|\n",
      "|     1|     47|   5.0|964983815|\n",
      "|     1|     50|   5.0|964982931|\n",
      "+------+-------+------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|            rating|\n",
      "+-------+------------------+\n",
      "|  count|            100836|\n",
      "|   mean| 3.501556983616962|\n",
      "| stddev|1.0425292390606342|\n",
      "|    min|               0.5|\n",
      "|    max|               5.0|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings.describe(\"rating\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+---------+\n",
      "|userId|movieId|rating|timestamp|\n",
      "+------+-------+------+---------+\n",
      "|     1|   1219|   2.0|964983393|\n",
      "|     1|   2253|   2.0|964981775|\n",
      "|     1|   2338|   2.0|964983546|\n",
      "+------+-------+------+---------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings.filter(ratings['rating'] < 3.0).show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|rating|count|\n",
      "+------+-----+\n",
      "|   0.5| 1370|\n",
      "|   1.0| 2811|\n",
      "|   1.5| 1791|\n",
      "|   2.0| 7551|\n",
      "|   2.5| 5550|\n",
      "|   3.0|20047|\n",
      "|   3.5|13136|\n",
      "|   4.0|26818|\n",
      "|   4.5| 8551|\n",
      "|   5.0|13211|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings.groupBy(ratings['rating']).count().orderBy('rating').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.createOrReplaceTempView(\"movielens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+---------+\n",
      "|userId|movieId|rating|timestamp|\n",
      "+------+-------+------+---------+\n",
      "|     1|   1219|   2.0|964983393|\n",
      "|     1|   2253|   2.0|964981775|\n",
      "|     1|   2338|   2.0|964983546|\n",
      "+------+-------+------+---------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql(\"select * from movielens where rating < 3\").show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame from RDD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.textFile(\"data/movielens.txt\")\\\n",
    "        .map(lambda line: line.split(\",\"))\\\n",
    "        .map(lambda splits: (int(splits[0]), splits[1], splits[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 'Toy Story (1995)', 'Adventure|Animation|Children|Comedy|Fantasy')\n",
      "(2, 'Jumanji (1995)', 'Adventure|Children|Fantasy')\n",
      "(3, 'Grumpier Old Men (1995)', 'Comedy|Romance')\n",
      "(4, 'Waiting to Exhale (1995)', 'Comedy|Drama|Romance')\n",
      "(5, 'Father of the Bride Part II (1995)', 'Comedy')\n"
     ]
    }
   ],
   "source": [
    "for elem in rdd.take(5):\n",
    "    print(elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "id_field = StructField(\"id\", IntegerType(), True)\n",
    "title_field = StructField(\"title\", StringType(), True)\n",
    "genres_field = StructField(\"genres\", StringType(), True)\n",
    "\n",
    "schema = StructType([id_field, title_field, genres_field])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------------+\n",
      "| id|               title|              genres|\n",
      "+---+--------------------+--------------------+\n",
      "|  1|    Toy Story (1995)|Adventure|Animati...|\n",
      "|  2|      Jumanji (1995)|Adventure|Childre...|\n",
      "|  3|Grumpier Old Men ...|      Comedy|Romance|\n",
      "+---+--------------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movielens = sqlContext.createDataFrame(rdd, schema)\n",
    "\n",
    "movielens.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert df to RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(id=1, title='Toy Story (1995)', genres='Adventure|Animation|Children|Comedy|Fantasy')\n",
      "Row(id=2, title='Jumanji (1995)', genres='Adventure|Children|Fantasy')\n"
     ]
    }
   ],
   "source": [
    "movielensRDD = movielens.rdd\n",
    "\n",
    "for row in movielensRDD.take(2):\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = sqlContext.read.json(\"data/movies.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|               title|rating|\n",
      "+--------------------+------+\n",
      "|L'affaire Gordji,...|   6.3|\n",
      "|Le naufrage du La...|   6.8|\n",
      "|Le naufrage du La...|   6.8|\n",
      "|       Africa United|   6.2|\n",
      "|           Beginners|   7.2|\n",
      "+--------------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies.createOrReplaceTempView(\"movies\")\n",
    "\n",
    "nice_movies = sqlContext.sql(\"select title, rating from movies where rating > 4.9\")\n",
    "\n",
    "nice_movies.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save to json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "nice_movies.write.json(\"data/nice_movies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apache Parquet\n",
    "\n",
    "Apache Parquet is a popular column-oriented storage format, which is supported by a wide variety of data processing systems. It is often used with tools in the Hadoop ecosystem and supports all of the data types in Spark SQL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.write.parquet('data/movielens.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read Parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parquet = sqlContext.read.parquet('data/movielens.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|               title|rating|\n",
      "+--------------------+------+\n",
      "|Bucky Larson : Bo...|   3.0|\n",
      "|               Krach|   4.3|\n",
      "|      L'élève Ducobu|   4.6|\n",
      "|    Piège à Hongkong|   4.3|\n",
      "|      Street fighter|   3.4|\n",
      "+--------------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_parquet.createOrReplaceTempView('parquetlens')\n",
    "\n",
    "just_movies = sqlContext.sql(\"select title, rating from parquetlens where rating between 2 and 5\")\n",
    "\n",
    "just_movies.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operations between df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = sc.parallelize([['a', 'foo'], ['b', 'hem'], ['c', 'haw']]).toDF(['a_id', 'extra'])\n",
    "b = sc.parallelize([['p1', 'a'], ['p2', 'b'], ['p3', 'c']]).toDF([\"other\", \"b_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|a_id|extra|\n",
      "+----+-----+\n",
      "|   a|  foo|\n",
      "|   b|  hem|\n",
      "|   c|  haw|\n",
      "+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+\n",
      "|other|b_id|\n",
      "+-----+----+\n",
      "|   p1|   a|\n",
      "|   p2|   b|\n",
      "|   p3|   c|\n",
      "+-----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "b.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+----+\n",
      "|a_id|extra|other|b_id|\n",
      "+----+-----+-----+----+\n",
      "|   c|  haw|   p3|   c|\n",
      "|   b|  hem|   p2|   b|\n",
      "|   a|  foo|   p1|   a|\n",
      "+----+-----+-----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "c = a.join(b, a.a_id == b.b_id, how='inner')\n",
    "\n",
    "c.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+----+\n",
      "|a_id|extra|other|b_id|\n",
      "+----+-----+-----+----+\n",
      "|   c|  haw|   p3|   c|\n",
      "|   b|  hem|   p2|   b|\n",
      "|   a|  foo|   p1|   a|\n",
      "+----+-----+-----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "c = a.join(b, a.a_id == b.b_id, how='left')\n",
    "\n",
    "c.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+----+\n",
      "|a_id|extra|other|b_id|\n",
      "+----+-----+-----+----+\n",
      "|   a|  foo|   p1|   a|\n",
      "+----+-----+-----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "c.filter(~c['extra'].isin(['haw','hem'])).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
